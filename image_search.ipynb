{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import hamming, cosine\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_load(path, image_size):\n",
    "    \"\"\"\n",
    "    Load image\n",
    "\n",
    "    :param path: String, path to image\n",
    "    :image_size: tuple, size of output image\n",
    "    \"\"\"\n",
    "    \n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, image_size, cv2.INTER_CUBIC)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(data_path, labels_path, image_size, image_path_pickle):\n",
    "    \"\"\"\n",
    "    Load image and labels\n",
    "\n",
    "    :param data_path: String, path to train and test data\n",
    "    :param labels_path: String, path to label\n",
    "    :param image_size: tuple, single imaze size\n",
    "    :param image_path_pickle: String, name of a pickle file where all image will be saved\n",
    "    \"\"\"\n",
    "    with open(labels_path) as f:\n",
    "        classes = f.read().split(\"\\n\")[: -1]\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    # path to pickle\n",
    "    image_paths = []\n",
    "    \n",
    "    for image_name in os.listdir(data_path):\n",
    "        try:\n",
    "\n",
    "                # create full path to train data\n",
    "                image_path = os.path.join(data_path, image_name)\n",
    "                images.append(image_load(image_path, image_size))\n",
    "                image_paths.append(image_path)\n",
    "                for idx in range(len(classes)):\n",
    "                    if classes[idx] in image_name:\n",
    "                        labels.append(idx)\n",
    "        except:\n",
    "                pass\n",
    "    \n",
    "    with open(image_path_pickle + \".pickle\", \"wb\") as f:\n",
    "        pickle.dump(image_path, f)\n",
    "\n",
    "    assert len(images) == len(labels)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = data_preprocessing(\"dataset/train\", \"dataset/labels.txt\", (32, 32), \"training_image_pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(training_set_vector, query_vector, top_n=50):\n",
    "    \"\"\"\n",
    "    calculate cosine distance between query image and all trianing set image\n",
    "    \n",
    "    :param training_set_vector: numpy Matrix, vectors for all images in training set\n",
    "    :param query_vector: numpy vector, query image(new image)\n",
    "    :param top_n: interger, number of closest image to return\n",
    "    \"\"\"\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    for i in range(len(training_set_vector)): # for train dataset 50k image\n",
    "        distance.append(cosine(training_set_vector[i], query_vector[0]))\n",
    "    \n",
    "    return np.argsort(distance)[:top_n]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haming_distance(training_set_vector, query_vector, top_n=50):\n",
    "    \"\"\"\n",
    "    calculate haming distance between query image and all training images\n",
    "    \n",
    "    :param training_set_vector: numpy Matrix, vectors for all images in training set\n",
    "    :param query_vector: numpy vector, query image(new image)\n",
    "    :param top_n: interger, number of closest image to return\n",
    "    \"\"\"\n",
    "    \n",
    "    distance = []\n",
    "    \n",
    "    for i in range(len(training_set_vector)):\n",
    "        distance.append(hamming(training_set_vector[i], query_vector[0]))\n",
    "    \n",
    "    return np.argsort(distance)[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate accuracy of model on softmax outputs\n",
    "    \n",
    "    :param y_true: numpy array, true labels of each sample\n",
    "    :param y_pred: numpy matrix, softmax probabilities\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(y_true) == len(y_pred)\n",
    "    \n",
    "    correct += 1\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        if np.argnax(y_pred)[i] == y_true[i]:\n",
    "                correct += 1\n",
    "    \n",
    "    return correct / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, number_of_filter, kernel_size, stride=(1, 1),\n",
    "                padding=\"SAME\", activation=\"tf.nn.relu\",\n",
    "                max_pool=True, batch_norm=True):\n",
    "        \n",
    "        \"\"\"\n",
    "        define convolutional block layer\n",
    "\n",
    "        :param number_of_filter: interger, number of filter\n",
    "        :param kernel_size: tuple, size of conv layer kernel\n",
    "        :param padding: String, type of padding SAME or VALID\n",
    "        :param activation: tf.object, activation functuin used on the layer\n",
    "        :param max_pool: boolean, true conv layer use max pooling\n",
    "        :param batch_norm: boolean, true conv layer use batch normalization\n",
    "        \"\"\"\n",
    "\n",
    "        super(Conv, self).__init__()\n",
    "\n",
    "        self.conv_layer = tf.keras.layers.Conv2D(filters=number_of_filter,\n",
    "                                                                                    kernel_size=kernel_size,\n",
    "                                                                                    strides=stride,\n",
    "                                                                                    padding=padding,\n",
    "                                                                                    activation=activation)\n",
    "\n",
    "        self.max_pool = max_pool\n",
    "        if max_pool:\n",
    "            self.max_pool_layer = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),\n",
    "                                                                                                  strides=(2, 2),\n",
    "                                                                                                  padding=\"SAME\")\n",
    "\n",
    "        self.batch_norm = batch_norm\n",
    "        if batch_norm:\n",
    "            self.batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        conv_features = x = self.conv_layer(inputs)\n",
    "        if self.max_pool:\n",
    "            x = self.max_pool_layer(x)\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm_layer(x, training)\n",
    "        \n",
    "        return x, conv_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, activation=tf.nn.relu, dropout=None, batch_norm=True):\n",
    "        \"\"\"\n",
    "        define Dense layer\n",
    "        \n",
    "        :param units: interger, number of neurons\n",
    "        :param activation: tf.object, activation functuin used on the layer\n",
    "        :param dropout: dropout rate\n",
    "        :param batch_norm: boolean, true conv layer use batch normalization\n",
    "        \"\"\"\n",
    "        \n",
    "        super(Dense, self).__init__()\n",
    "        \n",
    "        self.dense_layer = tf.keras.layers.Dense(units, activation=activation)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        if dropout is not None:\n",
    "            self.dropout_layer = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "        self.batch_norm = batch_norm\n",
    "        if batch_norm:\n",
    "            self.batch_norm_layer = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        dense_feature = x = self.dense_layer(inputs)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout_layer(x, training)\n",
    "        if self.batch_norm:\n",
    "            x = self.batch_norm_layer(x, training)\n",
    "        return x, dense_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, dropout, image_size, number_of_calsses=10):\n",
    "        \"\"\"\n",
    "        Build a model for image search\n",
    "        \n",
    "       :param dropout: dropout rate\n",
    "       :param image_size: tuple, (height, width)\n",
    "       :param number_of_calsses: integer, number of classes\n",
    "       \"\"\"\n",
    "        \n",
    "        super(BuildModel, self).__init__()\n",
    "        \n",
    "        self.batch_normalize_layer = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv_1 = Conv(number_of_filter=64,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        stride=(1, 1),\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        max_pool=True,\n",
    "                                        batch_norm=True)\n",
    "        \n",
    "        self.conv_2 = Conv(number_of_filter=128,\n",
    "                                        kernel_size=(3, 3),\n",
    "                                        stride=(1, 1),\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        max_pool=True,\n",
    "                                        batch_norm=True)\n",
    "        \n",
    "        self.conv_3 = Conv(number_of_filter=256,\n",
    "                                        kernel_size=(5, 5),\n",
    "                                        stride=(1, 1),\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        max_pool=True,\n",
    "                                        batch_norm=True)\n",
    "        \n",
    "        self.conv_3 = Conv(number_of_filter=512,\n",
    "                                        kernel_size=(5, 5),\n",
    "                                        stride=(1, 1),\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu,\n",
    "                                        max_pool=True,\n",
    "                                        batch_norm=True)\n",
    "\n",
    "        self.flatten_layer = tf.keras.layers.Flatten()\n",
    "        \n",
    "        self.dense_1 = Dense(units=128,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            dropout=dropout,\n",
    "                                            batch_norm=True)\n",
    "\n",
    "        self.dense_2 = Dense(units=256,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            dropout=dropout,\n",
    "                                            batch_norm=True)\n",
    "\n",
    "        self.dense_3 = Dense(units=512,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            dropout=dropout,\n",
    "                                            batch_norm=True)\n",
    "\n",
    "        self.dense_4 = Dense(units=1024,\n",
    "                                            activation=tf.nn.relu,\n",
    "                                            dropout=dropout,\n",
    "                                            batch_norm=True)\n",
    "        \n",
    "        self.final_dense = tf.keras.layers.Dense(units=number_of_calsses,\n",
    "                                                                        activation=None)\n",
    "        \n",
    "        self.final_siftmax = tf.keras.layers.Softmax()\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = self.batch_normalize_layer(inputs, training)\n",
    "        x, conv1 = self.conv_1(x, training)\n",
    "        x, conv2 = self.conv_2(x, training)\n",
    "        x, conv3 = self.conv_3(x, training)\n",
    "        x, conv4 = self.conv_4(x, training)\n",
    "        \n",
    "        x = self.flatten_layer(x)\n",
    "        \n",
    "        x, dense1 = self.dense_1(x, training)\n",
    "        x, dense2 = self.dense_2(x, training)\n",
    "        x, dense3 = self.dense_3(x, training)\n",
    "        x, dense4 = self.dense_4(x, training)\n",
    "        \n",
    "        x = self.final_dense(x)\n",
    "        output = self.final_siftmax(x)\n",
    "        \n",
    "        return output, dense2, dense4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BuildModel(0.5, (32, 32), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
